{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johanvandenhoogen/opt/anaconda3/envs/ee/lib/python3.6/site-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
      "    from google.appengine.api import memcache\n",
      "ModuleNotFoundError: No module named 'google.appengine'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johanvandenhoogen/opt/anaconda3/envs/ee/lib/python3.6/site-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
      "    from oauth2client.contrib.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johanvandenhoogen/opt/anaconda3/envs/ee/lib/python3.6/site-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
      "    from oauth2client.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johanvandenhoogen/opt/anaconda3/envs/ee/lib/python3.6/site-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
      "    from . import file_cache\n",
      "  File \"/Users/johanvandenhoogen/opt/anaconda3/envs/ee/lib/python3.6/site-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
      "    'file_cache is unavailable when using oauth2client >= 4.0.0')\n",
      "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0\n",
      "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johanvandenhoogen/opt/anaconda3/envs/ee/lib/python3.6/site-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
      "    from google.appengine.api import memcache\n",
      "ModuleNotFoundError: No module named 'google.appengine'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johanvandenhoogen/opt/anaconda3/envs/ee/lib/python3.6/site-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
      "    from oauth2client.contrib.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johanvandenhoogen/opt/anaconda3/envs/ee/lib/python3.6/site-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
      "    from oauth2client.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johanvandenhoogen/opt/anaconda3/envs/ee/lib/python3.6/site-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
      "    from . import file_cache\n",
      "  File \"/Users/johanvandenhoogen/opt/anaconda3/envs/ee/lib/python3.6/site-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
      "    'file_cache is unavailable when using oauth2client >= 4.0.0')\n",
      "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules for the protocol\n",
    "import ee as ee\n",
    "ee.Initialize()\n",
    "import pandas as pd\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the proportion of variance that you would like to cover when running the script\n",
    "propOfVariance = 90\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def assessExtrapolation(importedData, compositeImage, propOfVariance):\n",
    "    \n",
    "    # Excise the columns of interest from the data frame\n",
    "    variablesOfInterest = importedData\n",
    "#     variablesOfInterest = importedData.drop(['system:index', '.geo'], axis=1)\n",
    "    \n",
    "    # Compute the mean and standard deviation of each band, then standardize the point data\n",
    "    meanVector = variablesOfInterest.mean()\n",
    "    stdVector = variablesOfInterest.std()\n",
    "    standardizedData = (variablesOfInterest-meanVector)/stdVector\n",
    "    \n",
    "    # Then standardize the composite from which the points were sampled\n",
    "    meanList = meanVector.tolist()\n",
    "    stdList = stdVector.tolist()\n",
    "    bandNames = list(meanVector.index)\n",
    "    meanImage = ee.Image(meanList).rename(bandNames)\n",
    "    stdImage = ee.Image(stdList).rename(bandNames)\n",
    "    standardizedImage = compositeImage.subtract(meanImage).divide(stdImage)\n",
    "    \n",
    "    # Run a PCA on the point samples\n",
    "    pcaOutput = PCA()\n",
    "    pcaOutput.fit(standardizedData)\n",
    "    \n",
    "    # Save the cumulative variance represented by each PC\n",
    "    cumulativeVariance = np.cumsum(np.round(pcaOutput.explained_variance_ratio_, decimals=4)*100)\n",
    "    \n",
    "    # Make a list of PC names for future organizational purposes\n",
    "    pcNames = ['PC'+str(x) for x in range(1,variablesOfInterest.shape[1]+1)]\n",
    "    \n",
    "    # Get the PC loadings as a data frame\n",
    "    loadingsDF = pd.DataFrame(pcaOutput.components_,columns=[str(x)+'_Loads' for x in bandNames],index=pcNames)\n",
    "    \n",
    "    # Get the original data transformed into PC space\n",
    "    transformedData = pd.DataFrame(pcaOutput.fit_transform(standardizedData,standardizedData),columns=pcNames)\n",
    "    \n",
    "    # Make principal components images, multiplying the standardized image by each of the eigenvectors\n",
    "    # Collect each one of the images in a single image collection;\n",
    "    \n",
    "    # First step: make an image collection wherein each image is a PC loadings image\n",
    "    listOfLoadings = ee.List(loadingsDF.values.tolist());\n",
    "    eePCNames = ee.List(pcNames)\n",
    "    zippedList = eePCNames.zip(listOfLoadings)\n",
    "    def makeLoadingsImage(zippedValue):\n",
    "        return ee.Image.constant(ee.List(zippedValue).get(1)).rename(bandNames).set('PC',ee.List(zippedValue).get(0))\n",
    "    loadingsImageCollection = ee.ImageCollection(zippedList.map(makeLoadingsImage))\n",
    "    \n",
    "    # Second step: multiply each of the loadings image by the standardized image and reduce it using a \"sum\"\n",
    "    # to finalize the matrix multiplication\n",
    "    def finalizePCImages(loadingsImage):\n",
    "        return ee.Image(loadingsImage).multiply(standardizedImage).reduce('sum').rename([ee.String(ee.Image(loadingsImage).get('PC'))]).set('PC',ee.String(ee.Image(loadingsImage).get('PC')))\n",
    "    principalComponentsImages = loadingsImageCollection.map(finalizePCImages)\n",
    "    \n",
    "    # Choose how many principal components are of interest in this analysis based on amount of\n",
    "    # variance explained\n",
    "    numberOfComponents = sum(i < propOfVariance for i in cumulativeVariance)+1\n",
    "    print('Number of Principal Components being used:',numberOfComponents)\n",
    "    \n",
    "    # Compute the combinations of the principal components being used to compute the 2-D convex hulls\n",
    "    tupleCombinations = list(combinations(list(pcNames[0:numberOfComponents]),2))\n",
    "    print('Number of Combinations being used:',len(tupleCombinations))\n",
    "    \n",
    "    # Generate convex hulls for an example of the principal components of interest\n",
    "    cHullCoordsList = list()\n",
    "    for c in tupleCombinations:\n",
    "        firstPC = c[0]\n",
    "        secondPC = c[1]\n",
    "        outputCHull = ConvexHull(transformedData[[firstPC,secondPC]])\n",
    "        listOfCoordinates = transformedData.loc[outputCHull.vertices][[firstPC,secondPC]].values.tolist()\n",
    "        flattenedList = [val for sublist in listOfCoordinates for val in sublist]\n",
    "        cHullCoordsList.append(flattenedList)\n",
    "    \n",
    "    # Reformat the image collection to an image with band names that can be selected programmatically\n",
    "    pcImage = principalComponentsImages.toBands().rename(pcNames)\n",
    "    \n",
    "    # Generate an image collection with each PC selected with it's matching PC\n",
    "    listOfPCs = ee.List(tupleCombinations)\n",
    "    listOfCHullCoords = ee.List(cHullCoordsList)\n",
    "    zippedListPCsAndCHulls = listOfPCs.zip(listOfCHullCoords)\n",
    "    \n",
    "    def makeToClassifyImages(zippedListPCsAndCHulls):\n",
    "        imageToClassify = pcImage.select(ee.List(zippedListPCsAndCHulls).get(0)).set('CHullCoords',ee.List(zippedListPCsAndCHulls).get(1))\n",
    "        classifiedImage = imageToClassify.rename('u','v').classify(ee.Classifier.spectralRegion([imageToClassify.get('CHullCoords')]))\n",
    "        return classifiedImage\n",
    "    classifedImages = ee.ImageCollection(zippedListPCsAndCHulls.map(makeToClassifyImages))\n",
    "    finalImageToExport = classifedImages.sum().divide(ee.Image.constant(len(tupleCombinations)))\n",
    "    \n",
    "    return finalImageToExport\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthList = [[0,5],[5,15]]\n",
    "monthList = list(range(1,13))\n",
    "\n",
    "# Load a geometry to use for the export\n",
    "exportingGeometry = ee.Geometry.Polygon([[[-180, 88], [180, 88], [180, -88], [-180, -88]]], None, False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth interval: 0 - 5 cm\n",
      "1\n",
      "Number of Principal Components being used: 11\n",
      "Number of Combinations being used: 55\n",
      "2\n",
      "Number of Principal Components being used: 11\n",
      "Number of Combinations being used: 55\n",
      "3\n",
      "Number of Principal Components being used: 11\n",
      "Number of Combinations being used: 55\n",
      "4\n",
      "Number of Principal Components being used: 11\n",
      "Number of Combinations being used: 55\n",
      "5\n",
      "Number of Principal Components being used: 12\n",
      "Number of Combinations being used: 66\n",
      "6\n",
      "Number of Principal Components being used: 12\n",
      "Number of Combinations being used: 66\n",
      "7\n",
      "Number of Principal Components being used: 12\n",
      "Number of Combinations being used: 66\n",
      "8\n",
      "Number of Principal Components being used: 12\n",
      "Number of Combinations being used: 66\n",
      "9\n",
      "Number of Principal Components being used: 12\n",
      "Number of Combinations being used: 66\n",
      "10\n",
      "Number of Principal Components being used: 11\n",
      "Number of Combinations being used: 55\n",
      "11\n",
      "Number of Principal Components being used: 12\n",
      "Number of Combinations being used: 66\n",
      "12\n",
      "Number of Principal Components being used: 11\n",
      "Number of Combinations being used: 55\n",
      "Depth interval: 5 - 15 cm\n",
      "1\n",
      "Number of Principal Components being used: 11\n",
      "Number of Combinations being used: 55\n",
      "2\n",
      "Number of Principal Components being used: 11\n",
      "Number of Combinations being used: 55\n",
      "3\n",
      "Number of Principal Components being used: 11\n",
      "Number of Combinations being used: 55\n",
      "4\n",
      "Number of Principal Components being used: 11\n",
      "Number of Combinations being used: 55\n",
      "5\n",
      "Number of Principal Components being used: 11\n",
      "Number of Combinations being used: 55\n",
      "6\n",
      "Number of Principal Components being used: 11\n",
      "Number of Combinations being used: 55\n",
      "7\n",
      "Number of Principal Components being used: 12\n",
      "Number of Combinations being used: 66\n",
      "8\n",
      "Number of Principal Components being used: 11\n",
      "Number of Combinations being used: 55\n",
      "9\n",
      "Number of Principal Components being used: 11\n",
      "Number of Combinations being used: 55\n",
      "10\n",
      "Number of Principal Components being used: 10\n",
      "Number of Combinations being used: 45\n",
      "11\n",
      "Number of Principal Components being used: 11\n",
      "Number of Combinations being used: 55\n",
      "12\n",
      "Number of Principal Components being used: 10\n",
      "Number of Combinations being used: 45\n"
     ]
    }
   ],
   "source": [
    "for depth in depthList:\n",
    "    print('Depth interval:', depth[0], '-', depth[1], 'cm')\n",
    "    PCAimageList = []\n",
    "    for month in monthList:  \n",
    "        print(month)\n",
    "        \n",
    "        # Input a list of the covariates being used\n",
    "        staticCovarList = [\n",
    "        'Aridity_Index',\n",
    "        'EarthEnvTopoMed_1stOrderPartialDerivEW',\n",
    "        'EarthEnvTopoMed_Elevation',\n",
    "        'EarthEnvTopoMed_Roughness',\n",
    "        'EarthEnvTopoMed_TerrainRuggednessIndex',\n",
    "        'GlobBiomass_AboveGroundBiomass',\n",
    "        'Human_Development_Percentage',\n",
    "        'LandCoverClass_Barren',\n",
    "        'Nadir_Reflectance_Band1',\n",
    "        'Nadir_Reflectance_Band2',\n",
    "        'Nadir_Reflectance_Band3',\n",
    "        'Nadir_Reflectance_Band4',\n",
    "        'Nadir_Reflectance_Band5',\n",
    "        'Nadir_Reflectance_Band6',\n",
    "        'Nadir_Reflectance_Band7',\n",
    "        'NDVI',\n",
    "        'PET',\n",
    "        'Population_Density',\n",
    "        'SG_Absolute_depth_to_bedrock',\n",
    "        'SG_Bulk_density_005cm',\n",
    "        'SG_Depth_to_bedrock',\n",
    "        'SG_Sand_Content_005cm',\n",
    "        'SG_SOC_Density_005cm',\n",
    "        'SG_Soil_pH_H2O_005cm'\n",
    "        ];\n",
    "\n",
    "        # Monthly variable names\n",
    "        monthly_vars = [\n",
    "        \"EarthEnvCloudCover_MODCF_monthlymean_\"+str(month).zfill(2),\n",
    "        \"WorldClim2_H2OVaporPressure_Month\"+str(month).zfill(2),\n",
    "        \"WorldClim2_SolarRadiation_Month\"+str(month).zfill(2)\n",
    "        ];\n",
    "\n",
    "        # Cloud cover has NA values for December\n",
    "        if month == 1 or month == 12:\n",
    "            del monthly_vars[0]\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        classProperty = 'deltaT_'+str(month).zfill(2)\n",
    "\n",
    "        # Load the composite on which to perform the mapping, and subselect the bands of interest\n",
    "        compositeToUse = ee.Image(\"projects/crowtherlab/johan/CrowtherLab_Composite_30ArcSec_2019\").select(staticCovarList+monthly_vars)\n",
    "\n",
    "        # Monthly climate variables from CHELSA\n",
    "        CHELSA_monthly = ee.Image('users/johanvandenhoogen/000_CHELSA_monthly/CHELSA_monthly_'+str(month).zfill(2))\n",
    "\n",
    "        # CHELSA variable names\n",
    "        CHELSA_vars = CHELSA_monthly.bandNames().getInfo()\n",
    "    \n",
    "        # Monthly snow cover\n",
    "        snowCover = ee.Image('users/johanvandenhoogen/000_composites/monthly_snowcover/SnowCover_'+str(month).zfill(2)).rename(\"snowCover_\"+str(month).zfill(2))\n",
    "\n",
    "        # Snowcover variable name\n",
    "        snowCover_var = \"snowCover_\"+str(month).zfill(2)\n",
    "    \n",
    "        # Full list of variables to be included\n",
    "        covariateList = staticCovarList+monthly_vars+CHELSA_vars+[snowCover_var]\n",
    "        \n",
    "        # Construct final composite\n",
    "        compositeToClassify = ee.Image.cat(\n",
    "            compositeToUse,\n",
    "            CHELSA_monthly,\n",
    "            snowCover\n",
    "            )\n",
    "\n",
    "        # Import data\n",
    "        sampled_data = pd.read_csv('data/training_data/'+str(depth[0])+'_'+str(depth[1])+'cm_/'+classProperty+'/'+classProperty+'CV_Fold_Collection.csv')[covariateList]\n",
    "                \n",
    "        # Apply the function\n",
    "        finalImageToExport_SoilT = assessExtrapolation(sampled_data, compositeToClassify, propOfVariance)\n",
    "        \n",
    "        PCAimageList.append(finalImageToExport_SoilT.toFloat())\n",
    "        \n",
    "        task = ee.batch.Export.image.toAsset(\n",
    "            image = finalImageToExport_SoilT.toFloat(),\n",
    "            description = str(depth[0])+'_'+str(depth[1])+classProperty+'PCA_CHull_IntExt',\n",
    "            assetId = 'users/johanvandenhoogen/2020_soil_temperature_v6/PCA_int_extImgs/'+str(depth[0])+'_'+str(depth[1])+'_'+classProperty+'_PCA_CHull_IntExt',\n",
    "            crs = 'EPSG:4326',\n",
    "            crsTransform = '[0.008333333333333333,0,-180,0,-0.008333333333333333,90]',\n",
    "            region = exportingGeometry,\n",
    "            maxPixels = int(1e13)\n",
    "        );\n",
    "\n",
    "#         task.start()\n",
    "        \n",
    "    meanImage = ee.ImageCollection.fromImages(PCAimageList).reduce(\n",
    "        reducer = ee.Reducer.mean()\n",
    "    )\n",
    "\n",
    "    meanImageExport = ee.batch.Export.image.toAsset(\n",
    "        image = meanImage.toFloat(),\n",
    "        description = str(depth[0])+'_'+str(depth[1])+'_PCA_int_ext_mean_image',\n",
    "        assetId = 'users/johanvandenhoogen/2020_soil_temperature_v6/'+str(depth[0])+'_'+str(depth[1])+'_PCA_int_ext_mean_image' ,\n",
    "        crs = 'EPSG:4326',\n",
    "        crsTransform = '[0.008333333333333333,0,-180,0,-0.008333333333333333,90]',\n",
    "        region = exportingGeometry,\n",
    "        maxPixels = int(1e13)\n",
    "    );\n",
    "    meanImageExport.start()\n",
    "\n",
    "    meanImageExport = ee.batch.Export.image.toDrive(\n",
    "        image = meanImage.multiply(100).toInt().toFloat().divide(100),\n",
    "        description = str(depth[0])+'_'+str(depth[1])+'_PCA_int_ext_mean_image',\n",
    "        folder = 'soil_temperature',\n",
    "        crs = 'EPSG:4326',\n",
    "        crsTransform = '[0.04166666666666667,0,-180,0,-0.04166666666666667,90]',\n",
    "        region = exportingGeometry,\n",
    "        maxPixels = int(1e13)\n",
    "    );\n",
    "\n",
    "#     meanImageExport.start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
